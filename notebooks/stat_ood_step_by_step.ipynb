{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ”¬ Stat-OOD: Step-by-Step Analysis\n",
                "\n",
                "This notebook breaks down the Stat-OOD pipeline into modular steps. Use this to inspect data, check model outputs, and understand how OOD scores are calculated internally."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "075eb07d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Mon Jan 12 06:23:32 2026       \n",
                        "+-----------------------------------------------------------------------------------------+\n",
                        "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
                        "|-----------------------------------------+------------------------+----------------------+\n",
                        "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
                        "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
                        "|                                         |                        |               MIG M. |\n",
                        "|=========================================+========================+======================|\n",
                        "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
                        "| N/A   34C    P8              8W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
                        "|                                         |                        |                  N/A |\n",
                        "+-----------------------------------------+------------------------+----------------------+\n",
                        "                                                                                         \n",
                        "+-----------------------------------------------------------------------------------------+\n",
                        "| Processes:                                                                              |\n",
                        "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
                        "|        ID   ID                                                               Usage      |\n",
                        "|=========================================================================================|\n",
                        "|  No running processes found                                                             |\n",
                        "+-----------------------------------------------------------------------------------------+\n"
                    ]
                }
            ],
            "source": [
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup Environment (Colab Only)\n",
                "# Uncomment if running on Colab\n",
                "# !pip install -q uv\n",
                "# !git clone https://github.com/sucpark/stat-ood.git\n",
                "# %cd stat-ood\n",
                "# !uv sync\n",
                "\n",
                "import sys\n",
                "import os\n",
                "sys.path.append(os.getcwd()) # Ensure src is visible"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'src'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipython-input-438911902.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0momegaconf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOmegaConf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOODCalculator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'",
                        "",
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "from omegaconf import OmegaConf\n",
                "from src.data.loader import DataLoader\n",
                "from src.models.wrapper import ModelWrapper\n",
                "from src.ood.calculator import OODCalculator\n",
                "from transformers import AutoTokenizer\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Manual Configuration\n",
                "cfg = OmegaConf.create({\n",
                "    \"name\": \"stat-ood-analysis\",\n",
                "    \"dataset\": {\n",
                "        \"name\": \"clinc_oos\",\n",
                "        \"subset\": \"plus\",\n",
                "        \"maxlen\": 64,\n",
                "        \"loader\": {\n",
                "            \"batch_size\": 32,\n",
                "            \"num_workers\": 0,\n",
                "            \"pin_memory\": False\n",
                "        }\n",
                "    },\n",
                "    \"model\": {\n",
                "        \"name\": \"bert-base-uncased\",\n",
                "        \"num_labels\": 150,\n",
                "        \"pooling\": \"cls\" \n",
                "    },\n",
                "    \"ood_method\": \"mahalanobis\", # or 'energy'\n",
                "    \"experiment\": {\n",
                "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "    }\n",
                "})\n",
                "\n",
                "device = torch.device(cfg.experiment.device)\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tokenizer = AutoTokenizer.from_pretrained(cfg.model.name)\n",
                "loader = DataLoader(cfg.dataset, tokenizer)\n",
                "train_loader, val_loader, test_id_loader, test_ood_loader = loader.load()\n",
                "\n",
                "print(f\"Train Batches: {len(train_loader)}\")\n",
                "batch = next(iter(train_loader))\n",
                "print(f\"Sample Batch Keys: {batch.keys()}\")\n",
                "print(f\"Input Shape: {batch['input_ids'].shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Initialize Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = ModelWrapper(cfg.model)\n",
                "model.to(device)\n",
                "model.eval()\n",
                "print(\"Model initialized successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Extract Features (Simulated Fitting)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Extracting features from Training set for fitting statistics...\")\n",
                "train_features = []\n",
                "train_labels = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    # Limit to 5 batches for quick demo\n",
                "    for i, batch in enumerate(train_loader):\n",
                "        if i > 5: break\n",
                "        input_ids = batch['input_ids'].to(device)\n",
                "        mask = batch['attention_mask'].to(device)\n",
                "        labels = batch['intent'].to(device)\n",
                "        \n",
                "        # Forward\n",
                "        model(input_ids, mask)\n",
                "        \n",
                "        if cfg.ood_method == 'energy':\n",
                "            feats = model.get_features('logits')\n",
                "        else:\n",
                "            feats = model.get_features('pooled_output')\n",
                "            \n",
                "        train_features.append(feats.cpu())\n",
                "        train_labels.append(labels.cpu())\n",
                "\n",
                "train_features = torch.cat(train_features)\n",
                "train_labels = torch.cat(train_labels)\n",
                "print(f\"Extracted Features Shape: {train_features.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Fit OOD Calculator"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ood_calc = OODCalculator(cfg)\n",
                "ood_calc.fit(train_features, train_labels)\n",
                "print(\"OOD Calculator fitted.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Score Analysis (ID vs OOD)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_scores(loader, limit=5):\n",
                "    scores = []\n",
                "    with torch.no_grad():\n",
                "        for i, batch in enumerate(loader):\n",
                "            if i >= limit: break\n",
                "            input_ids = batch['input_ids'].to(device)\n",
                "            mask = batch['attention_mask'].to(device)\n",
                "            \n",
                "            model(input_ids, mask)\n",
                "            \n",
                "            if cfg.ood_method == 'energy':\n",
                "                feats = model.get_features('logits')\n",
                "            else:\n",
                "                feats = model.get_features('pooled_output')\n",
                "            \n",
                "            dists = ood_calc.predict(feats)\n",
                "            scores.append(dists)\n",
                "    return torch.cat(scores)\n",
                "\n",
                "id_scores = get_scores(test_id_loader)\n",
                "ood_scores = get_scores(test_ood_loader)\n",
                "\n",
                "# Plot\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.kdeplot(id_scores.numpy(), label='ID (Known Intents)', fill=True)\n",
                "sns.kdeplot(ood_scores.numpy(), label='OOD (Unknown)', fill=True)\n",
                "plt.title(f\"OOD Score Distribution ({cfg.ood_method})\")\n",
                "plt.xlabel(\"Score (Distance/Energy)\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
